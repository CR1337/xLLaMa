version: '3.3'

services:

  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - 12345:11434
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ['0']
            capabilities: [gpu]

  frontend:
    build: services/frontend
    container_name: frontend
    ports:
      - 8080:5173
    depends_on:
      - llm_facade

  llm_facade:
    build: services/llm_facade
    container_name: llm_facade
    ports:
      - 8081:5000
    depends_on:
      - ollama
    env_file:
      - services/llm_facade/.env
