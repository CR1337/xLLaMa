version: '3.3'

services:

  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - 12345:11434
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #       - driver: nvidia
    #         device_ids: ['2', '3']
    #         capabilities: [gpu]

  frontend:
    build: services/frontend
    container_name: frontend
    ports:
      - 8080:5173
    depends_on:
      - llm_facade

  llm_facade:
    build: services/llm_facade
    container_name: llm_facade
    ports:
      - 8081:5000
    depends_on:
      - ollama
      - code_analyzer
    env_file:
      - services/llm_facade/.env

  code_analyzer:
    build: services/code_analyzer
    container_name: code_analyzer
    ports:
      - 8082:5001
